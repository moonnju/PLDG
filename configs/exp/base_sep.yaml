# arguments for training
epochs: 80
epoch_rampup: 20
iters: 1000
batch_size: 2
optimizer: sgd
lr: 0.1
weight_decay: 0.0001
lr_scheduler: plateau
lr_kwargs:
  mode: "min"
  factor: 0.8 # reduce by 20%
  patience: 5
  threshold: 1.0e-3
  verbose: True
  min_lr: 0.01
