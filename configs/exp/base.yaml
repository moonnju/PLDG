# arguments for training
epochs: 80
epoch_rampup: 20
iters: 1000
batch_size: 4
optimizer: sgd
lr: 0.3
weight_decay: 0.0001
lr_scheduler: plateau
lr_kwargs:
  mode: "min"
  factor: 0.8 # reduce by 20%
  patience: 5
  threshold: 1.0e-3
  verbose: True
  min_lr: 0.03

conf_thresh: 0.9

lambda_dice: 4.0
